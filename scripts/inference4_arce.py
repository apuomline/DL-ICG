"""
tta+ç±»åˆ«å¹³è¡¡åå¤„ç† - æ”¯æŒ400ç±»åˆ«å’Œ5000ç±»åˆ« - ä¿®å¤ç‰ˆæœ¬ï¼ˆæ”¯æŒArcFaceæ¨¡å‹ï¼‰
ç®€åŒ–ç‰ˆæœ¬ï¼šç§»é™¤ç±»åˆ«å¹³è¡¡ä»£ç ï¼Œä½¿ç”¨YAMLé…ç½®
"""

import os
import yaml
import numpy as np
import torch
import torchvision
from torchvision import transforms
from PIL import Image
import timm
import glob
from tqdm import tqdm
import json
import csv
from collections import defaultdict
import math
import torch.nn as nn
import torch.nn.functional as F

# ============================ ArcFace Head å®ç°ï¼ˆä¸è®­ç»ƒä»£ç ä¸€è‡´ï¼‰ ============================

class NormLinear(nn.Linear):
    """å½’ä¸€åŒ–çº¿æ€§å±‚"""
    def __init__(self,
                 in_features: int,
                 out_features: int,
                 bias: bool = False,
                 feature_norm: bool = True,
                 weight_norm: bool = True):
        super().__init__(in_features, out_features, bias=bias)
        self.weight_norm = weight_norm
        self.feature_norm = feature_norm

    def forward(self, input: torch.Tensor) -> torch.Tensor:
        if self.feature_norm:
            input = F.normalize(input)
        if self.weight_norm:
            weight = F.normalize(self.weight)
        else:
            weight = self.weight
        return F.linear(input, weight, self.bias)

class SubCenterNormLinear(nn.Linear):
    """å­ä¸­å¿ƒå½’ä¸€åŒ–çº¿æ€§å±‚"""
    def __init__(self,
                 in_features: int,
                 out_features: int,
                 bias: bool = False,
                 k=3,
                 feature_norm: bool = True,
                 weight_norm: bool = True):
        super().__init__(in_features, out_features * k, bias=bias)
        self.weight_norm = weight_norm
        self.feature_norm = feature_norm
        self.out_features = out_features
        self.k = k

    def forward(self, input: torch.Tensor) -> torch.Tensor:
        if self.feature_norm:
            input = F.normalize(input)
        if self.weight_norm:
            weight = F.normalize(self.weight)
        else:
            weight = self.weight
        cosine_all = F.linear(input, weight, self.bias)
        cosine_all = cosine_all.view(-1, self.out_features, self.k)
        cosine, _ = torch.max(cosine_all, dim=2)
        return cosine

class ArcFaceHead(nn.Module):
    """ArcFaceåˆ†ç±»å¤´"""
    def __init__(self,
                 num_classes: int,
                 in_channels: int,
                 s: float = 30.0,
                 m: float = 0.50,
                 number_sub_center: int = 1,
                 easy_margin: bool = False,
                 ls_eps: float = 0.0,
                 bias: bool = False):
        super(ArcFaceHead, self).__init__()
        
        self.in_channels = in_channels
        self.num_classes = num_classes
        self.s = s
        self.m = m
        self.ls_eps = ls_eps

        if self.num_classes <= 0:
            raise ValueError(f'num_classes={num_classes} must be a positive integer')

        self.easy_margin = easy_margin
        self.th = math.cos(math.pi - m)
        self.mm = math.sin(math.pi - m) * m

        assert number_sub_center >= 1
        if number_sub_center == 1:
            self.norm_linear = NormLinear(in_channels, num_classes, bias=bias)
        else:
            self.norm_linear = SubCenterNormLinear(
                in_channels, num_classes, bias=bias, k=number_sub_center)

    def forward(self, features: torch.Tensor, target = None) -> torch.Tensor:
        """å‰å‘ä¼ æ’­"""
        # ç¡®ä¿åœ¨FP32ç²¾åº¦ä¸‹è®¡ç®—
        features = features.float()
        
        # cos=(a*b)/(||a||*||b||)
        cosine = self.norm_linear(features)

        if target is None:
            # æµ‹è¯•é˜¶æ®µï¼Œç›´æ¥è¿”å›cosineä¹˜scale
            return self.s * cosine

        # è®­ç»ƒé˜¶æ®µï¼Œåº”ç”¨ArcFaceè¾¹é™…
        phi = torch.cos(torch.acos(cosine) + self.m)

        if self.easy_margin:
            phi = torch.where(cosine > 0, phi, cosine)
        else:
            phi = torch.where(cosine > self.th, phi, cosine - self.mm)

        # åˆ›å»ºone-hotç¼–ç 
        one_hot = torch.zeros(cosine.size(), device=features.device)
        one_hot.scatter_(1, target.view(-1, 1).long(), 1)
        
        if self.ls_eps > 0:
            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.num_classes

        # ç»„åˆè¾“å‡º
        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)
        return output * self.s

# ============================ æ¨¡å‹åˆ›å»ºå‡½æ•°ï¼ˆä¸è®­ç»ƒä»£ç ä¸€è‡´ï¼‰ ============================

def create_efficientnet_arcface_model(model_name, num_classes, checkpoint_path, arcface_s=30.0, arcface_m=0.5, number_sub_center=1):
    """åˆ›å»ºEfficientNet + ArcFaceæ¨¡å‹ï¼ˆä¸è®­ç»ƒä»£ç ä¸€è‡´ï¼‰"""
    print(f"Creating {model_name} model with {num_classes} classes and ArcFace head")
    
    # åˆ›å»ºEfficientNetéª¨å¹²ç½‘ç»œ
    print(f"Creating model without pretrained weights, will load from: {checkpoint_path}")
    backbone = timm.create_model(model_name, pretrained=False, num_classes=num_classes)
    
    # è·å–ç‰¹å¾ç»´åº¦
    with torch.no_grad():
        dummy_input = torch.randn(1, 3, 384, 384)  # ä½¿ç”¨å›ºå®šçš„image_size
        features = backbone(dummy_input)
        feature_dim = features.shape[1]
        print(f"Feature dimension: {feature_dim}")
    
    # åˆ›å»ºArcFaceåˆ†ç±»å¤´
    arcface_head = ArcFaceHead(
        num_classes=num_classes,
        in_channels=feature_dim,
        s=arcface_s,
        m=arcface_m,
        number_sub_center=number_sub_center,
        easy_margin=False,
        ls_eps=0.0,
        bias=False
    )
    
    # ç»„åˆæˆå®Œæ•´æ¨¡å‹
    class EfficientNetArcFaceModel(nn.Module):
        def __init__(self, backbone, head):
            super().__init__()
            self.backbone = backbone
            self.head = head
            
        def forward(self, x, target=None):
            features = self.backbone(x)
            return self.head(features, target)
    
    model = EfficientNetArcFaceModel(backbone, arcface_head)
    
    # åŠ è½½è®­ç»ƒå¥½çš„æƒé‡
    print(f"Loading checkpoint from: {checkpoint_path}")
    checkpoint = torch.load(checkpoint_path, map_location='cpu')
    
    # å¤„ç†ä¸åŒçš„state_dictæ ¼å¼
    if 'state_dict' in checkpoint:
        state_dict = checkpoint['state_dict']
    elif 'model' in checkpoint:
        state_dict = checkpoint['model']
    else:
        state_dict = checkpoint
    
    # å¤„ç†æƒé‡é”®å
    new_state_dict = {}
    for k, v in state_dict.items():
        # ç§»é™¤å¯èƒ½å­˜åœ¨çš„module.å‰ç¼€
        if k.startswith('module.'):
            k = k[7:]
        new_state_dict[k] = v
    
    # åŠ è½½æƒé‡
    missing_keys, unexpected_keys = model.load_state_dict(new_state_dict, strict=True)
    
    if missing_keys:
        print(f"âš ï¸ ç¼ºå¤±çš„é”®: {len(missing_keys)} ä¸ª")
        for i, key in enumerate(missing_keys[:10]):
            print(f"  {i+1}. {key}")
        if len(missing_keys) > 10:
            print(f"  ... è¿˜æœ‰ {len(missing_keys) - 10} ä¸ªç¼ºå¤±çš„é”®")
    
    if unexpected_keys:
        print(f"âš ï¸ æ„å¤–çš„é”®: {len(unexpected_keys)} ä¸ª")
        for i, key in enumerate(unexpected_keys[:10]):
            print(f"  {i+1}. {key}")
        if len(unexpected_keys) > 10:
            print(f"  ... è¿˜æœ‰ {len(unexpected_keys) - 10} ä¸ªæ„å¤–çš„é”®")
    
    print(f"âœ… æˆåŠŸåŠ è½½æ¨¡å‹æƒé‡")
    return model

# ============================ å…¶ä»–å‡½æ•°ä¿æŒä¸å˜ ============================

def setup_seed(seed):
    """è®¾ç½®éšæœºç§å­"""
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

def build_test_transform(image_size: int, mean, std):
    """æ„å»ºæµ‹è¯•æ—¶çš„æ•°æ®é¢„å¤„ç†æµç¨‹"""
    test_tf = transforms.Compose([
        transforms.Lambda(lambda img: img.convert('RGB') if img.mode != 'RGB' else img),
        transforms.Resize(image_size),
        transforms.CenterCrop(image_size),
        transforms.ToTensor(),
        transforms.Normalize(mean=mean, std=std),
    ])
    return test_tf

def load_image_paths(test_dir):
    """åŠ è½½æµ‹è¯•ç›®å½•ä¸‹çš„æ‰€æœ‰å›¾åƒè·¯å¾„"""
    # æ”¯æŒçš„å›¾åƒæ ¼å¼
    ALLOWED_EXTS = ('.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm', '.tif', '.tiff', '.webp',
                    '.gif', '.jfif')
    
    image_paths = []
    for ext in ALLOWED_EXTS:
        pattern = os.path.join(test_dir, f'*{ext}')
        image_paths.extend(glob.glob(pattern))
        pattern = os.path.join(test_dir, f'*{ext.upper()}')
        image_paths.extend(glob.glob(pattern))
    
    # å»é‡å¹¶æ’åº
    image_paths = sorted(list(set(image_paths)))
    print(f"æ‰¾åˆ° {len(image_paths)} å¼ æµ‹è¯•å›¾åƒ")
    return image_paths

def tta_forward(model, inputs):
    """TTAå‰å‘ä¼ æ’­"""
    # åŸå§‹é¢„æµ‹
    ori_out = model(inputs)
    # æ°´å¹³ç¿»è½¬é¢„æµ‹
    flip_out = model(inputs.flip(3))  # åœ¨ç»´åº¦3ï¼ˆå®½åº¦ï¼‰ä¸Šç¿»è½¬
    # å–å¹³å‡
    out = (ori_out + flip_out) / 2
    return out

def predict_single_image(model, image_path, transform, device, use_tta=True):
    """å¯¹å•å¼ å›¾åƒè¿›è¡Œé¢„æµ‹"""
    try:
        # åŠ è½½å›¾åƒ
        image = Image.open(image_path)
        
        # åº”ç”¨é¢„å¤„ç†
        input_tensor = transform(image).unsqueeze(0).to(device)
        
        # æ¨¡å‹æ¨ç†
        model.eval()
        with torch.no_grad():
            if use_tta:
                # ä½¿ç”¨TTAï¼ˆæ°´å¹³ç¿»è½¬å¢å¼ºï¼‰
                logits = tta_forward(model, input_tensor)
            else:
                logits = model(input_tensor)  # æ³¨æ„ï¼šè¿™é‡Œä¸éœ€è¦targetå‚æ•°
            
            # è®¡ç®—æ¦‚ç‡å’Œé¢„æµ‹ç±»åˆ«
            probabilities = torch.softmax(logits, dim=1)
            confidence, predicted_class = torch.max(probabilities, 1)
            
            confidence = confidence.item()
            predicted_class = predicted_class.item()
            full_probabilities = probabilities.cpu().numpy()[0]  # è·å–å®Œæ•´æ¦‚ç‡å‘é‡
            
        return predicted_class, confidence, full_probabilities, True
        
    except Exception as e:
        print(f"å¤„ç†å›¾åƒ {image_path} æ—¶å‡ºé”™: {e}")
        return -1, 0.0, None, False

def predict_batch_images(model, image_paths, transform, device, batch_size=32, use_tta=True):
    """æ‰¹é‡é¢„æµ‹å›¾åƒ"""
    results = []
    all_probabilities = []
    
    for i in tqdm(range(0, len(image_paths), batch_size), desc="æ¨ç†è¿›åº¦"):
        batch_paths = image_paths[i:i+batch_size]
        batch_images = []
        valid_indices = []
        
        # åŠ è½½å’Œé¢„å¤„ç†æ‰¹æ¬¡å›¾åƒ
        for j, img_path in enumerate(batch_paths):
            try:
                image = Image.open(img_path)
                input_tensor = transform(image)
                batch_images.append(input_tensor)
                valid_indices.append(j)
            except Exception as e:
                print(f"åŠ è½½å›¾åƒ {img_path} å¤±è´¥: {e}")
                continue
        
        if not batch_images:
            continue
            
        # å †å å¼ é‡
        batch_tensor = torch.stack(batch_images).to(device)
        
        # æ¨¡å‹æ¨ç†
        model.eval()
        with torch.no_grad():
            if use_tta:
                # ä½¿ç”¨TTAï¼ˆæ°´å¹³ç¿»è½¬å¢å¼ºï¼‰
                logits = tta_forward(model, batch_tensor)
            else:
                logits = model(batch_tensor)  # æ³¨æ„ï¼šè¿™é‡Œä¸éœ€è¦targetå‚æ•°
            
            # è®¡ç®—æ¦‚ç‡å’Œé¢„æµ‹ç±»åˆ«
            probabilities = torch.softmax(logits, dim=1)
            confidences, predicted_classes = torch.max(probabilities, 1)
            
            # æ”¶é›†ç»“æœ
            batch_probs = probabilities.cpu().numpy()
            for idx, (img_idx, pred_class, conf) in enumerate(zip(valid_indices, predicted_classes, confidences)):
                original_idx = i + img_idx
                results.append({
                    'image_path': batch_paths[img_idx],
                    'predicted_class': pred_class.item(),
                    'confidence': conf.item(),
                    'status': 'success'
                })
                all_probabilities.append(batch_probs[idx])
    
    # å¤„ç†å¤±è´¥çš„æƒ…å†µ
    success_paths = {r['image_path'] for r in results}
    for img_path in image_paths:
        if img_path not in success_paths:
            results.append({
                'image_path': img_path,
                'predicted_class': -1,
                'confidence': 0.0,
                'status': 'failed'
            })
            # å¯¹äºå¤±è´¥çš„å›¾åƒï¼Œæ·»åŠ å‡åŒ€åˆ†å¸ƒçš„æ¦‚ç‡
            if all_probabilities:  # ç¡®ä¿è‡³å°‘æœ‰ä¸€ä¸ªæˆåŠŸçš„æ¦‚ç‡å‘é‡
                all_probabilities.append(np.ones(len(all_probabilities[0])) / len(all_probabilities[0]))
            else:
                # å¦‚æœå®Œå…¨æ²¡æœ‰æˆåŠŸçš„æ¨ç†ï¼Œåˆ›å»ºä¸€ä¸ªé»˜è®¤çš„æ¦‚ç‡å‘é‡
                all_probabilities.append(np.ones(5000) / 5000)  # å‡è®¾5000ç±»
    
    return results, all_probabilities

def save_submission_csv(results, output_file='submission.csv', num_classes=400):
    """ä¿å­˜é¢„æµ‹ç»“æœä¸ºCSVæ–‡ä»¶"""
    with open(output_file, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        for result in results:
            # è·å–å›¾ç‰‡æ–‡ä»¶å
            image_filename = os.path.basename(result['image_path'])
            
            # è·å–é¢„æµ‹ç±»åˆ«ï¼Œå¦‚æœæ˜¯å¤±è´¥çš„æƒ…å†µé»˜è®¤è®¾ä¸º0000æˆ–00000
            if result['status'] == 'success':
                predicted_class = result['predicted_class']
                # æ ¹æ®ç±»åˆ«æ•°é‡å†³å®šæ ¼å¼
                if num_classes <= 400:
                    class_str = f"{predicted_class:04d}"
                else:
                    class_str = f"{predicted_class:05d}"
            else:
                # é¢„æµ‹å¤±è´¥æ—¶ä½¿ç”¨é»˜è®¤ç±»åˆ«
                if num_classes <= 400:
                    class_str = "0000"
                else:
                    class_str = "00000"
            
            # å†™å…¥CSVæ–‡ä»¶ï¼Œæ ¼å¼ï¼šæ–‡ä»¶å, ç±»åˆ«
            writer.writerow([image_filename, class_str])
    
    print(f"âœ… æäº¤æ–‡ä»¶å·²ç”Ÿæˆ: {output_file}")
    print(f"ğŸ“Š æ€»å›¾åƒæ•°é‡: {len(results)}")

def load_config(config_path):
    """åŠ è½½YAMLé…ç½®æ–‡ä»¶"""
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    return config

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='ä½¿ç”¨è®­ç»ƒå¥½çš„EfficientNet+ArcFaceæ¨¡å‹è¿›è¡Œå›¾åƒåˆ†ç±»æ¨ç†ï¼ˆYAMLé…ç½®ç‰ˆæœ¬ï¼‰')
    parser.add_argument('--config', type=str, required=True, help='YAMLé…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--test_dir', type=str, help='æµ‹è¯•ç›®å½•è·¯å¾„ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®ï¼‰')
    parser.add_argument('--checkpoint_path', type=str, help='æ¨¡å‹æƒé‡è·¯å¾„ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®ï¼‰')
    parser.add_argument('--output_file', type=str, help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®ï¼‰')
    
    args = parser.parse_args()
    
    # åŠ è½½é…ç½®æ–‡ä»¶
    if not os.path.exists(args.config):
        print(f"é”™è¯¯: é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.config}")
        return
    
    config = load_config(args.config)
    
    # ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°è¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®
    if args.test_dir:
        config['test_dir'] = args.test_dir
    if args.checkpoint_path:
        config['checkpoint_path'] = args.checkpoint_path
    if args.output_file:
        config['output_file'] = args.output_file
    
    # è®¾ç½®éšæœºç§å­
    setup_seed(config.get('seed', 42))
    
    # æ£€æŸ¥è¾“å…¥ç›®å½•
    if not os.path.exists(config['test_dir']):
        print(f"é”™è¯¯: æµ‹è¯•ç›®å½•ä¸å­˜åœ¨: {config['test_dir']}")
        return
    
    if not os.path.exists(config['checkpoint_path']):
        print(f"é”™è¯¯: æ¨¡å‹æƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {config['checkpoint_path']}")
        return
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device(config.get('device', 'cuda' if torch.cuda.is_available() else 'cpu'))
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # æ„å»ºæ•°æ®é¢„å¤„ç†
    normalize_mean = config.get('normalize_mean', [0.485, 0.456, 0.406])
    normalize_std = config.get('normalize_std', [0.229, 0.224, 0.225])
    
    test_transform = build_test_transform(config['image_size'], normalize_mean, normalize_std)
    
    # åˆ›å»ºæ¨¡å‹å¹¶åŠ è½½æƒé‡ï¼ˆä½¿ç”¨ArcFaceç‰ˆæœ¬ï¼‰
    model = create_efficientnet_arcface_model(
        model_name=config['model_name'],
        num_classes=config['num_classes'],
        checkpoint_path=config['checkpoint_path'],
        arcface_s=config.get('arcface_s', 30.0),
        arcface_m=config.get('arcface_m', 0.5),
        number_sub_center=config.get('number_sub_center', 1)
    )
    model = model.to(device)
    
    # å¦‚æœä½¿ç”¨å¤šGPUï¼Œéœ€è¦åŒ…è£…
    if torch.cuda.device_count() > 1:
        model = torch.nn.DataParallel(model)
        print(f"ä½¿ç”¨DataParallelï¼ŒGPUæ•°é‡: {torch.cuda.device_count()}")
    
    # åŠ è½½æµ‹è¯•å›¾åƒ
    image_paths = load_image_paths(config['test_dir'])
    if not image_paths:
        print("åœ¨æµ‹è¯•ç›®å½•ä¸­æœªæ‰¾åˆ°ä»»ä½•å›¾åƒæ–‡ä»¶")
        return
    
    # è¿›è¡Œæ¨ç†
    use_tta = config.get('use_tta', True)
    batch_size = config.get('batch_size', 32)
    
    print(f"å¼€å§‹æ¨ç†ï¼Œä½¿ç”¨{'TTA' if use_tta else 'æ— TTA'}ï¼Œæ‰¹æ¬¡å¤§å°: {batch_size}")
    
    if batch_size == 1:
        # å•å¼ å›¾åƒæ¨ç†
        results = []
        all_probabilities = []
        for img_path in tqdm(image_paths, desc="æ¨ç†è¿›åº¦"):
            pred_class, confidence, probabilities, success = predict_single_image(
                model, img_path, test_transform, device, use_tta
            )
            results.append({
                'image_path': img_path,
                'predicted_class': pred_class,
                'confidence': confidence,
                'status': 'success' if success else 'failed'
            })
            if success:
                all_probabilities.append(probabilities)
            else:
                all_probabilities.append(np.ones(config['num_classes']) / config['num_classes'])
    else:
        # æ‰¹é‡æ¨ç†
        results, all_probabilities = predict_batch_images(
            model, image_paths, test_transform, device, batch_size, use_tta
        )
    
    # ä¿å­˜æ¨ç†ç»“æœ
    save_submission_csv(results, config['output_file'], config['num_classes'])
    
    # æ‰“å°ç»“æœç»Ÿè®¡
    successful = [r for r in results if r['status'] == 'success']
    print(f"\næ¨ç†å®Œæˆ!")
    print(f"æ€»å›¾åƒ: {len(results)}")
    print(f"æˆåŠŸ: {len(successful)}")
    print(f"å¤±è´¥: {len(results) - len(successful)}")
    
    if successful:
        avg_conf = np.mean([r['confidence'] for r in successful])
        print(f"å¹³å‡ç½®ä¿¡åº¦: {avg_conf:.4f}")

if __name__ == '__main__':
    main()